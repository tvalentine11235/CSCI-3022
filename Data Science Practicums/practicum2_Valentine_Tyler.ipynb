{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "\n",
    "# CSCI 3022: Intro to Data Science - Spring 2019 Practicum 2\n",
    "***\n",
    "\n",
    "This practicum is due on Canvas by **11:59 PM on Friday May 3**. Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.  Your solutions to computational questions should include any specified Python code and results as well as written commentary on your conclusions.  \n",
    "\n",
    "**Here are the rules:** \n",
    "\n",
    "1. All work, code and analysis, must be your own. \n",
    "1. You may use your course notes, posted lecture slides, textbooks, in-class notebooks, and homework solutions as resources.  You may also search online for answers to general knowledge questions like the form of a probability distribution function or how to perform a particular operation in Python/Pandas. \n",
    "1. This is meant to be like a coding portion of your midterm exam. So, the instructional team will be much less helpful than we typically are with homework. For example, we will not check answers, help debug your code, and so on.\n",
    "1. If something is left open-ended, it is because we want to see how you approach the kinds of problems you will encounter in the wild, where it will not always be clear what sort of tests/methods should be applied. Feel free to ask clarifying questions though.\n",
    "2. You may **NOT** post to message boards or other online resources asking for help.\n",
    "3. You may **NOT** copy-paste solutions *from anywhere*.\n",
    "4. You may **NOT** collaborate with classmates or anyone else.\n",
    "5. In short, **your work must be your own**. It really is that simple.\n",
    "\n",
    "Violation of the above rules will result in an immediate academic sanction (*at the very least*, you will receive a 0 on this practicum or an F in the course, depending on severity), and a trip to the Honor Code Council.\n",
    "\n",
    "**By submitting this assignment, you agree to abide by the rules given above.**\n",
    "\n",
    "***\n",
    "\n",
    "**Name**:  \n",
    "\n",
    "Tyler Valentine\n",
    "\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- You may not use late days on the practicums nor can you drop your practicum grades. \n",
    "- If you have a question for us, post it as a **PRIVATE** message on Piazza.  If we decide that the question is appropriate for the entire class, then we will add it to a Practicum clarifications thread. \n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda 3.6. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Canvas.  Do not compress it using tar, rar, zip, etc. \n",
    "- This should go without saying, but... For any question that asks you to calculate something, you **must show all work to receive credit**. Sparse or nonexistent work will receive sparse or nonexistent credit.\n",
    "\n",
    "---\n",
    "**Shortcuts:**  [Problem 1](#p1) | [Problem 2](#p2) | [Bottom](#bot)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy import stats\n",
    "import statsmodels.api as sm \n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "<a id='p1'></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "### [30 points] Problem 1:  What's the best Oreo flavor?\n",
    "\n",
    "> <img src=\"https://media2.s-nbcnews.com/j/newscms/2015_52/1351976/151223-watermelon-oreos-flickr-yh-1234p_a4c4ba1016261e5d799a789666948a6e.fit-760w.jpg\" style=\"width: 400px;\"/>\n",
    "**Figure 1.** Watermelon Oreos. These are undeniably the absolute _worst_ Oreo flavor, but not a part of our data set. If they were, the problem would be too easy.\n",
    "\n",
    "You're skipping down the road one day, singing a merry tune without a care in the world. Every so often you hop and click your heels together. After one such hop, though, you stumble and nearly trip. Under your feet is a fun data set!\n",
    "\n",
    "In particular, this rascally data set includes ratings from 5 different individuals for 12 different types of Oreo cookie. Because some of the raters are allergic to disgusting flavors of Oreo, not every taster tasted every type of cookie. More information about the data set can be found [here](https://www.kaggle.com/rtatman/oreo-flavors-tastetest-ratings).\n",
    "\n",
    "As you examine the data, a booming voice from the sky instructs you to analyze the data to answer two key questions:\n",
    "1. is there some difference in mean rating given to different flavors of Oreo? and\n",
    "2. which flavor (out of those in the data set) is the best?\n",
    "\n",
    "**Part A:** Load the data set as a Pandas DataFrame. Then, process it as you see fit. For the analysis, you might create a new DataFrame, or other kinds of Python objects to use the data. Do what feels right, and include an **explanation** in Markdown of how you are processing the data. You **may not** alter the original data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rater_n</th>\n",
       "      <th>rater_c</th>\n",
       "      <th>rater_r</th>\n",
       "      <th>rater_k</th>\n",
       "      <th>rater_a</th>\n",
       "      <th>average_across_raters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50</td>\n",
       "      <td>2.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.7000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3.8125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.50</td>\n",
       "      <td>4.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rater_n  rater_c  rater_r  rater_k  rater_a  average_across_raters\n",
       "0       1.5      4.0      2.0      NaN      NaN                 2.5000\n",
       "1       2.5      3.0      4.0      NaN     1.50                 2.7500\n",
       "2       4.5      3.5      1.5      NaN     3.50                 3.2500\n",
       "3       3.5      3.0      3.5      3.0     4.00                 3.4000\n",
       "4       2.5      5.0      2.5      4.0     3.00                 3.4000\n",
       "5       3.5      4.0      3.0      3.0     3.50                 3.4000\n",
       "6       4.0      3.0      4.5      4.0     2.50                 3.6000\n",
       "7       2.5      1.0      5.0      5.0     5.00                 3.7000\n",
       "8       3.0      4.0      4.0      NaN     4.25                 3.8125\n",
       "9       3.5      4.5      3.0      4.5     4.50                 4.0000\n",
       "10      3.5      4.0      4.5      4.0     4.25                 4.0500\n",
       "11      NaN      4.5      4.5      4.5     4.00                 4.3750"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfOreo = pd.read_csv(\"D:\\Valentine\\CU\\CSCI-3022\\Practicum_2\\oreo_rankings.csv\", na_values = '-')\n",
    "dfOreo2 = pd.read_csv(\"D:\\Valentine\\CU\\CSCI-3022\\Practicum_2\\oreo_rankings.csv\", na_values = '-')\n",
    "#dfOreo.dropna()\n",
    "del (dfOreo['notes_and_discussion'])\n",
    "del (dfOreo['oreo_flavor'])\n",
    "dfOreo.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER PART A**\n",
    "\n",
    "In order for the data to be more useable for later parts of this question I got rid of all of of the columns that didn't contain numerical data. I also set data points that had no values to NaN so that I could perform a check to skip them later in the problem. Finally, I made a backup dataframe so that I could reference that information in case it was needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B:** In the remainder of this problem, you will perform some hypothesis tests to examine whether these data suggest there are significant differences in the mean ratings of the different Oreo flavors. Pick a level of significance for these experiments, and explain how you decided to use that significance level. \"Because we used it a lot in class\" is ***not*** a good reason."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**ANSWER PART B**\n",
    "\n",
    "Determining if there are significant differences in the mean ratings of Oreos is serious business! I am using a 99% level of significance in order to obtain an accurate assesment of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C:** Perform an **Analysis of Variance hypothesis test** in order to determine if there is evidence that there is _some_ difference among the mean ratings given to these 12 Oreo flavors. Clearly state your null and alternative hypothesis, and use the significance level identified in **Part B**. You must show **all** calculations **by hand** (and may of course use Python as a calculator, and to compute values from a distribution using the appropriate percent-point-function (ppf) or cumulative distribution function (cdf)).\n",
    "\n",
    "In addition to showing the code for your calculations, make comments **in Markdown** explaining what you are doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HYPOTHESIS PART C**\n",
    "\n",
    "$H_0: \\mu_1 = \\mu_2 = ... = \\mu_i$ There is not a significant difference between the mean ratings.\n",
    "\n",
    "$H_1: \\mu_i \\ne \\mu_j$ for some pair $i,j$ There is a significant difference between the mean ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2598909843303179 0.0008345423550680797\n"
     ]
    }
   ],
   "source": [
    "grandMean = dfOreo['average_across_raters'].mean()\n",
    "SSB = 0\n",
    "SSW = 0\n",
    "SSBdf = 11\n",
    "SSWdf = 42\n",
    "for i in range (12):\n",
    "    SSB = SSB + 12*((dfOreo['average_across_raters'][i]-grandMean)**2) \n",
    "\n",
    "for i in range (12):\n",
    "    mean = dfOreo.iloc[i,5]\n",
    "    for j in range (5):\n",
    "        if (np.isnan(dfOreo.iloc[i,j]) == False):\n",
    "            SSW = SSW + ((dfOreo.iloc[i,j]-mean)**2)\n",
    "\n",
    "SST = SSB+SSW\n",
    "F = (SSB/SSBdf)/(SSW/SSWdf)\n",
    "rej_reg = stats.f.ppf(.01,dfn=11,dfd=42)\n",
    "p = 1-(stats.f.cdf(F,11,42))\n",
    "print(rej_reg,p)\n",
    "\n",
    "\n",
    "\n",
    "#print(dfOreo.iloc[0,5])       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER PART C**\n",
    "\n",
    "1. Our first step will be to find the grand mean of all of the groups (flavors)\n",
    "\n",
    "2. Next I will calculate the SSB and SSW values:\n",
    "    \n",
    "    SSB is equal to the number groups multiplied by each row mean minus the overall grand mean squared for each row all added together. It looks like this:\n",
    "    $SSB = ([12(2.5-3.52)^2] + [12(2.75-3.52)^2] + [12(3.25-3.52)^2] + [12(3.4-3.52)^2] + [12(3.4-3.52)^2] + [12(3.4-3.52)^2] + [12(3.6-3.52)^2] + [12(3.7-3.52)^2] + [12(3.8125-3.52)^2] + [12(4-3.52)^2] + [12(4.05-3.52)^2] + [12(4.375-3.52)^2]) = 37.393$\n",
    "    \n",
    "    To calculate the SSW for all 54 values I subtract the mean for the given row from each score in that row, square that value, and add it to a running total of SSW values. It looks like this:\n",
    "    $SSW = ( 1.5 - 2.5 ) ^2 +( 4.0 - 2.5 ) ^2 +( 2.0 - 2.5 ) ^2 +( 2.5 - 2.75 ) ^2 +( 3.0 - 2.75 ) ^2 +( 4.0 - 2.75 ) ^2 +( 1.5 - 2.75 ) ^2 +( 4.5 - 3.25 ) ^2 +( 3.5 - 3.25 ) ^2 +( 1.5 - 3.25 ) ^2 +( 3.5 - 3.25 ) ^2 +( 3.5 - 3.4 ) ^2 +( 3.0 - 3.4 ) ^2 +( 3.5 - 3.4 ) ^2 +( 3.0 - 3.4 ) ^2 +( 4.0 - 3.4 ) ^2 +( 2.5 - 3.4 ) ^2 +( 5.0 - 3.4 ) ^2 +( 2.5 - 3.4 ) ^2 +( 4.0 - 3.4 ) ^2 +( 3.0 - 3.4 ) ^2 +( 3.5 - 3.4 ) ^2 +( 4.0 - 3.4 ) ^2 +( 3.0 - 3.4 ) ^2 +( 3.0 - 3.4 ) ^2 +( 3.5 - 3.4 ) ^2 +( 4.0 - 3.6 ) ^2 +( 3.0 - 3.6 ) ^2 +( 4.5 - 3.6 ) ^2 +( 4.0 - 3.6 ) ^2 +( 2.5 - 3.6 ) ^2 +( 2.5 - 3.7 ) ^2 +( 1.0 - 3.7 ) ^2 +( 5.0 - 3.7 ) ^2 +( 5.0 - 3.7 ) ^2 +( 5.0 - 3.7 ) ^2 +( 3.0 - 3.8125 ) ^2 +( 4.0 - 3.8125 ) ^2 +( 4.0 - 3.8125 ) ^2 +( 4.25 - 3.8125 ) ^2 +( 3.5 - 4.0 ) ^2 +( 4.5 - 4.0 ) ^2 +( 3.0 - 4.0 ) ^2 +( 4.5 - 4.0 ) ^2 +( 4.5 - 4.0 ) ^2 +( 3.5 - 4.05 ) ^2 +( 4.0 - 4.05 ) ^2 +( 4.5 - 4.05 ) ^2 +( 4.0 - 4.05 ) ^2 +( 4.25 - 4.05 ) ^2 +( 4.5 - 4.375 ) ^2 +( 4.5 - 4.375 ) ^2 +( 4.5 - 4.375 ) ^2 +( 4.0 - 4.375 ) ^2 = 37.7593745$\n",
    "\n",
    "\n",
    "3. Now we can calculate our SST which is SSB+SSW and equals = 75.152343745\n",
    "\n",
    "4. Next we will calculate our degrees of freedom. $SSB_{DF} = I-1 = 12-1 = 11$ and $SSW_{DF} = N-I = 54-12 = 42$\n",
    "\n",
    "5. Now we can calculate our test statistic F. $F=\\frac{\\tfrac{SSB}{SSB_{DF}}}{\\tfrac{SSW}{SSW_{DF}}} =\\frac{\\tfrac{37.393}{11}}{\\tfrac{37.7593745}{42}} = 3.781131266317065$\n",
    "\n",
    "6. Finally we calculate the p-value $p = 1-stats.f.cdf(F,11,42) = .000835$. Because $.000835 < .01$ We reject the null hypothesis and say that there IS a significant difference between the mean ratings of the different flavors of Oreos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D:** Perform a **t hypothesis test** to determine if there is evidence supporting the claim that cinnamon bun Oreos have a higher mean rating than PB&J Oreos. Use the significance level you identified in **Part B**. Clearly state your null and alternative hypotheses, your conclusions, and show all work. Again, you may not use any canned t-test function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**HYPOTHESIS PART D**\n",
    "\n",
    "$H_0: \\mu_1 > \\mu_2$ Cinnamon Bun Oreos have a higher mean rating than PB&J Oreos\n",
    "\n",
    "$H_1: \\mu_i \\le \\mu_j$ Cinnamon Bun Oreos do not have a higher mean rating than PB&J Oreos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5 1.3228756555322954 4.375 0.25\n",
      "2.4227185592617446 0.9318148774623103\n"
     ]
    }
   ],
   "source": [
    "pbjMean = dfOreo.iloc[0,5]\n",
    "cbMean = dfOreo.iloc[11,5]\n",
    "pbjSD = dfOreo.iloc[0,0:3].std()\n",
    "cbSD = dfOreo.iloc[11,1:5].std()\n",
    "print(pbjMean,pbjSD,cbMean,cbSD)\n",
    "t = (cbMean - pbjMean)/(np.sqrt(((cbSD**2)/4)+((pbjSD**2)/3)))\n",
    "df = 2\n",
    "p = stats.t.cdf(t,df=2)\n",
    "print(t,p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER PART D**\n",
    "\n",
    "Peanut Butter and Jelly Mean = 2.5\n",
    "Peanut Butter and Jelly SD = 1.3229\n",
    "Cinnamon Bun Mean = 4.375\n",
    "Cinnamon Bun SD = .25\n",
    "\n",
    "$t = \\frac{4.375-2.5}{\\sqrt{\\tfrac{.25^2}{4}+\\tfrac{1.3229^2}{3}}} = 2.42271856$\n",
    "\n",
    "Using a conservative degrees of freedom value of 2 we get:\n",
    "\n",
    "$p = stats.t.cdf(2.42271856, df=2) = .93181488$\n",
    "\n",
    "Because $.93 > .01$  we fail to reject the Null Hypothesis and can say that Cinnamon Bun Oreos have a higher mean rating than PB&J Oreos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E:** Do your results from Parts C and D agree with one another? If they agree, explain how they are in agreement in _words_. If they do not agree, explain why you think they do not agree.\n",
    "\n",
    "_Hint: if they do not agree, consider carefully what assumptions we make in ANOVA and the t-test._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**ANSWER PART E**\n",
    "\n",
    "They do agree! In part C, the null hypothesis stated that all of the means of the samples were the same. We found that we needed to reject the null hypothesis thus concluded that there is a difference between the sameple means. In part D the hypothesis was that there was a difference between the means. The p value was much larger than the alpha value so we failed to reject the null hypothesis and again determined that there was a difference between the means. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "<a id='p2'></a>\n",
    "[Back to top](#top)\n",
    "\n",
    "### [30 points] Problem 2: Multiple Linear Regression to Explain House Hauntings\n",
    "\n",
    "<img src=\"https://s-media-cache-ak0.pinimg.com/originals/09/72/01/09720128cff5de4d4af038cd3fcf7f69.jpg\" style=\"width: 300px;\"/>\n",
    "\n",
    "In an effort to control the skyrocketing prices of real estate in the Colorado Front Range, Governor Polis implemented a cutting edge new intervention. This new program oversaw the introduction of ghosts back into their natural ecosystem, after the ghost population seriously dwindled in recent decades due to overhaunting. However, an unfortunate miscalculation has led to haunted houses becoming a very serious problem in Colorado. Modern problems require modern solutions, so Governor Polis has hired you and the famous hedgehog data scientist/part-time ghostbuster Amy to determine what features of a house may be used to best predict a `haunted` score, related to the probability that a house with the given features is haunted (higher $\\leftrightarrow$ more likely to be haunted).\n",
    "\n",
    "You decide to use multiple linear regression to understand and predict what factors lead to increased haunted house hazard. You collected a data set from Haunted Zillow, the lesser-known database of haunted house prices and attributes. The data cover a variety of potential features, and you'll find this data in the file `houses.csv`. \n",
    "\n",
    "**Response**: \n",
    "\n",
    "- $\\texttt{haunted}$: a haunting score, related to the probability that a house with the given features is haunted (higher $\\leftrightarrow$ more likely to be haunted)\n",
    "\n",
    "**Features**: \n",
    "\n",
    "- $\\texttt{age}$: age of the house, in years\n",
    "- $\\texttt{area}$: square footage of interior of house\n",
    "- $\\texttt{bathrooms}$: number of bathrooms\n",
    "- $\\texttt{distance metro}$: distance to the nearest major metropolitan area (in miles)\n",
    "- $\\texttt{distance cemetery}$: distance to the nearest cemetery (in miles)\n",
    "- $\\texttt{cats}$: the number of cats within a one-block radius of the house\n",
    "- $\\texttt{howls}$: the number of wolf howls heard on an average night in the house's neighborhood\n",
    "- $\\texttt{clouds}$: what percentage of the sky was covered by clouds (fraction, 0-1)\n",
    "- $\\texttt{precipitation}$: amount of precipitation in the past 72 hours (inches)\n",
    "- $\\texttt{misery index}$: an economic indicator for how miserable the average United States citizen is, based on the unemployment rate and the inflation rate. More [here](https://www.stuffyoushouldknow.com/podcasts/whats-the-misery-index.htm) and [here](https://en.wikipedia.org/wiki/Misery_index_(economics)). Higher values correspond to more miserable citizens.\n",
    "- $\\texttt{ice cream sold}$: the number of units of ice cream sold at the farmer's market the week the house was most recently sold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Read the data from `houses.csv` into a Pandas DataFrame.  Note that since we will be doing a multiple linear regression we will need all of the features, so you should drop any row in the DataFrame that is missing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>area</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>distance metro</th>\n",
       "      <th>distance cemetery</th>\n",
       "      <th>cats</th>\n",
       "      <th>howls</th>\n",
       "      <th>clouds</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>misery index</th>\n",
       "      <th>ice cream sold</th>\n",
       "      <th>haunted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.06</td>\n",
       "      <td>2041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>10.01</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>12.99</td>\n",
       "      <td>273</td>\n",
       "      <td>-0.596150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141.48</td>\n",
       "      <td>1564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.07</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>16.77</td>\n",
       "      <td>184</td>\n",
       "      <td>-0.146465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.58</td>\n",
       "      <td>1637</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.17</td>\n",
       "      <td>16.49</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.303117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.47</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.43</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.92</td>\n",
       "      <td>8.28</td>\n",
       "      <td>146</td>\n",
       "      <td>0.339912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>259.44</td>\n",
       "      <td>1642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.73</td>\n",
       "      <td>5.90</td>\n",
       "      <td>178</td>\n",
       "      <td>0.724867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>287.93</td>\n",
       "      <td>2676</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.57</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.37</td>\n",
       "      <td>8.59</td>\n",
       "      <td>186</td>\n",
       "      <td>0.805338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>86.92</td>\n",
       "      <td>2494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.69</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>16.55</td>\n",
       "      <td>259</td>\n",
       "      <td>-0.341216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>184.49</td>\n",
       "      <td>1157</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.13</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.88</td>\n",
       "      <td>6.07</td>\n",
       "      <td>105</td>\n",
       "      <td>0.182997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42.52</td>\n",
       "      <td>2520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.42</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>6.79</td>\n",
       "      <td>317</td>\n",
       "      <td>0.301654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150.29</td>\n",
       "      <td>1790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>7.32</td>\n",
       "      <td>285</td>\n",
       "      <td>0.152310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>143.29</td>\n",
       "      <td>2389</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.49</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.58</td>\n",
       "      <td>16.60</td>\n",
       "      <td>178</td>\n",
       "      <td>-0.045025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>41.97</td>\n",
       "      <td>2019</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.04</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.56</td>\n",
       "      <td>15.48</td>\n",
       "      <td>287</td>\n",
       "      <td>0.039757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>262.91</td>\n",
       "      <td>1985</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5.77</td>\n",
       "      <td>263</td>\n",
       "      <td>-0.073846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.31</td>\n",
       "      <td>2717</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.41</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.76</td>\n",
       "      <td>14.29</td>\n",
       "      <td>213</td>\n",
       "      <td>-0.483913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>296.44</td>\n",
       "      <td>1943</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.81</td>\n",
       "      <td>19.58</td>\n",
       "      <td>182</td>\n",
       "      <td>0.326364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>150.24</td>\n",
       "      <td>2002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.45</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.16</td>\n",
       "      <td>5.29</td>\n",
       "      <td>96</td>\n",
       "      <td>0.143042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>183.91</td>\n",
       "      <td>1812</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.43</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.28</td>\n",
       "      <td>9.46</td>\n",
       "      <td>122</td>\n",
       "      <td>0.031958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>131.00</td>\n",
       "      <td>1462</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.02</td>\n",
       "      <td>13.34</td>\n",
       "      <td>253</td>\n",
       "      <td>-0.503893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>244.76</td>\n",
       "      <td>2268</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.23</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>18.30</td>\n",
       "      <td>171</td>\n",
       "      <td>0.386117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>257.84</td>\n",
       "      <td>3010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.01</td>\n",
       "      <td>7.46</td>\n",
       "      <td>226</td>\n",
       "      <td>0.434018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>209.18</td>\n",
       "      <td>2132</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.31</td>\n",
       "      <td>7.75</td>\n",
       "      <td>181</td>\n",
       "      <td>0.304909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>47.93</td>\n",
       "      <td>1204</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3.08</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.15</td>\n",
       "      <td>8.29</td>\n",
       "      <td>226</td>\n",
       "      <td>-0.197762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>161.61</td>\n",
       "      <td>2377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>10.54</td>\n",
       "      <td>158</td>\n",
       "      <td>-0.178683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>272.04</td>\n",
       "      <td>1914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>15.67</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>14.91</td>\n",
       "      <td>253</td>\n",
       "      <td>-1.018351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>260.65</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.20</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.32</td>\n",
       "      <td>14.45</td>\n",
       "      <td>101</td>\n",
       "      <td>0.575107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>18.11</td>\n",
       "      <td>2705</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3.49</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.84</td>\n",
       "      <td>5.43</td>\n",
       "      <td>51</td>\n",
       "      <td>-0.281103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>57.38</td>\n",
       "      <td>3239</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.49</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.31</td>\n",
       "      <td>5.78</td>\n",
       "      <td>76</td>\n",
       "      <td>0.265246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>58.32</td>\n",
       "      <td>1708</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.02</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.00</td>\n",
       "      <td>269</td>\n",
       "      <td>-0.355040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>68.41</td>\n",
       "      <td>2114</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.03</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.12</td>\n",
       "      <td>7.93</td>\n",
       "      <td>191</td>\n",
       "      <td>0.183129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>28.96</td>\n",
       "      <td>2576</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.63</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>5.01</td>\n",
       "      <td>235</td>\n",
       "      <td>-0.085612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>108.81</td>\n",
       "      <td>2290</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.18</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>8.22</td>\n",
       "      <td>308</td>\n",
       "      <td>0.147214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10.73</td>\n",
       "      <td>2132</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.33</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>19.78</td>\n",
       "      <td>199</td>\n",
       "      <td>-0.128244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>224.76</td>\n",
       "      <td>1691</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.36</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.24</td>\n",
       "      <td>15.86</td>\n",
       "      <td>190</td>\n",
       "      <td>0.791066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>75.47</td>\n",
       "      <td>1668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5.43</td>\n",
       "      <td>77</td>\n",
       "      <td>0.087057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>43.20</td>\n",
       "      <td>1969</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4.22</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.55</td>\n",
       "      <td>14.34</td>\n",
       "      <td>104</td>\n",
       "      <td>0.112670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>257.67</td>\n",
       "      <td>1915</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>73.38</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.97</td>\n",
       "      <td>231</td>\n",
       "      <td>-6.559669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>36.35</td>\n",
       "      <td>948</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.33</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>11.87</td>\n",
       "      <td>189</td>\n",
       "      <td>-0.342452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>36.56</td>\n",
       "      <td>1375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>11.71</td>\n",
       "      <td>258</td>\n",
       "      <td>-0.155856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>253.65</td>\n",
       "      <td>2196</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.64</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.66</td>\n",
       "      <td>20.49</td>\n",
       "      <td>6</td>\n",
       "      <td>0.515447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>219.30</td>\n",
       "      <td>1891</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>3.52</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.91</td>\n",
       "      <td>10.51</td>\n",
       "      <td>183</td>\n",
       "      <td>0.154788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>200.38</td>\n",
       "      <td>2171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.21</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.38</td>\n",
       "      <td>20.51</td>\n",
       "      <td>104</td>\n",
       "      <td>0.108915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>102.13</td>\n",
       "      <td>2126</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.30</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>5.60</td>\n",
       "      <td>219</td>\n",
       "      <td>0.383989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>49.38</td>\n",
       "      <td>1824</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.59</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>16.78</td>\n",
       "      <td>200</td>\n",
       "      <td>0.045433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>135.57</td>\n",
       "      <td>2558</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>3.72</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.95</td>\n",
       "      <td>20.21</td>\n",
       "      <td>192</td>\n",
       "      <td>0.256072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>161.73</td>\n",
       "      <td>2122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.29</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.47</td>\n",
       "      <td>11.33</td>\n",
       "      <td>74</td>\n",
       "      <td>0.491245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>130.61</td>\n",
       "      <td>1441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.89</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.82</td>\n",
       "      <td>8.83</td>\n",
       "      <td>76</td>\n",
       "      <td>0.135198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>19.50</td>\n",
       "      <td>1906</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.53</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>20.46</td>\n",
       "      <td>241</td>\n",
       "      <td>-0.023704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>250.40</td>\n",
       "      <td>2232</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.26</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.55</td>\n",
       "      <td>14.39</td>\n",
       "      <td>65</td>\n",
       "      <td>0.172955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>264.88</td>\n",
       "      <td>1758</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.39</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.06</td>\n",
       "      <td>5.83</td>\n",
       "      <td>229</td>\n",
       "      <td>0.278635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>288.54</td>\n",
       "      <td>1520</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.36</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.18</td>\n",
       "      <td>18.48</td>\n",
       "      <td>146</td>\n",
       "      <td>0.167039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>55.47</td>\n",
       "      <td>1851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.13</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.96</td>\n",
       "      <td>15.33</td>\n",
       "      <td>268</td>\n",
       "      <td>-0.550824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>276.68</td>\n",
       "      <td>2234</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.69</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>7.83</td>\n",
       "      <td>313</td>\n",
       "      <td>0.227861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>233.89</td>\n",
       "      <td>2081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.02</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>14.98</td>\n",
       "      <td>216</td>\n",
       "      <td>-0.014516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>276.63</td>\n",
       "      <td>2006</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.22</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>20.89</td>\n",
       "      <td>286</td>\n",
       "      <td>0.224601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>191.93</td>\n",
       "      <td>1694</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.69</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.57</td>\n",
       "      <td>18.74</td>\n",
       "      <td>331</td>\n",
       "      <td>0.314783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>274.55</td>\n",
       "      <td>1768</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.76</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.38</td>\n",
       "      <td>11.17</td>\n",
       "      <td>116</td>\n",
       "      <td>0.534418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>75.30</td>\n",
       "      <td>1922</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.78</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.16</td>\n",
       "      <td>6.85</td>\n",
       "      <td>271</td>\n",
       "      <td>0.212597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>249.91</td>\n",
       "      <td>1820</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.94</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.67</td>\n",
       "      <td>16.83</td>\n",
       "      <td>211</td>\n",
       "      <td>-0.024468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>206.31</td>\n",
       "      <td>1886</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.01</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.46</td>\n",
       "      <td>19.44</td>\n",
       "      <td>122</td>\n",
       "      <td>0.219241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>260.45</td>\n",
       "      <td>1632</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.42</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.74</td>\n",
       "      <td>9.41</td>\n",
       "      <td>152</td>\n",
       "      <td>0.546907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  area  bathrooms  distance metro  distance cemetery  cats  howls  \\\n",
       "0    65.06  2041        1.0             7.1              10.01     7      3   \n",
       "1   141.48  1564        0.0             7.4               4.07     5      5   \n",
       "2     7.58  1637        3.0             7.0               3.36     2      0   \n",
       "3    51.47  2021        2.0             7.9               3.43     6      8   \n",
       "4   259.44  1642        1.0             7.5               3.19     4      1   \n",
       "5   287.93  2676        2.0             8.1               4.57     7      6   \n",
       "6    86.92  2494        0.0             7.1               4.69     4      4   \n",
       "7   184.49  1157        3.0             6.8               3.13     6      4   \n",
       "8    42.52  2520        1.0             6.1               3.42     3      3   \n",
       "9   150.29  1790        1.0             5.6               4.44     4      9   \n",
       "10  143.29  2389        2.0             8.1               5.49     2      2   \n",
       "11   41.97  2019        4.0             7.4               6.04     4      7   \n",
       "12  262.91  1985        2.0             5.5               6.88     7      7   \n",
       "13    7.31  2717        3.0             5.9               5.41     3      5   \n",
       "15  296.44  1943        2.0             6.3               3.65     3      4   \n",
       "16  150.24  2002        5.0             6.6               3.45     4      7   \n",
       "17  183.91  1812        5.0             7.5               3.43     5      9   \n",
       "18  131.00  1462        3.0             7.3              10.56     4      7   \n",
       "19  244.76  2268        2.0             7.4               6.23     6     10   \n",
       "20  257.84  3010        3.0             6.6               3.26     3      5   \n",
       "21  209.18  2132        3.0             6.1               4.19     4      2   \n",
       "22   47.93  1204        3.0             8.4               3.08     7      5   \n",
       "23  161.61  2377        1.0             8.3               6.80     1      8   \n",
       "24  272.04  1914        3.0             6.7              15.67     6      7   \n",
       "25  260.65  2013        2.0             6.0               3.20     3      7   \n",
       "27   18.11  2705        4.0             8.4               3.49     6      9   \n",
       "28   57.38  3239        4.0             5.5               7.49     9      5   \n",
       "29   58.32  1708        2.0             7.6               4.02     4      3   \n",
       "30   68.41  2114        3.0             5.5               3.03     4      4   \n",
       "31   28.96  2576        4.0             6.9               3.63     5      4   \n",
       "..     ...   ...        ...             ...                ...   ...    ...   \n",
       "41  108.81  2290        2.0             6.4               4.18     8      8   \n",
       "42   10.73  2132        2.0             7.9               3.33     5      9   \n",
       "43  224.76  1691        1.0             5.6               3.36    12      4   \n",
       "44   75.47  1668        0.0             7.0               3.52     3      3   \n",
       "45   43.20  1969        3.0             8.2               4.22     4      5   \n",
       "46  257.67  1915        3.0             7.8              73.38     7      6   \n",
       "47   36.35   948        5.0             8.0               5.33     6      8   \n",
       "48   36.56  1375        2.0             7.3               7.00     7      3   \n",
       "49  253.65  2196        2.0             7.6               4.64    17      8   \n",
       "50  219.30  1891        3.0             6.3               3.52     3      7   \n",
       "51  200.38  2171        1.0             6.9               7.21    12      2   \n",
       "52  102.13  2126        2.0             7.6               3.30     9      5   \n",
       "53   49.38  1824        2.0             7.0               4.59     0      5   \n",
       "54  135.57  2558        3.0             8.4               3.72     5      3   \n",
       "55  161.73  2122        0.0             6.9               3.29     9     12   \n",
       "56  130.61  1441        1.0             6.6               6.89     2      2   \n",
       "57   19.50  1906        3.0             5.8               4.53     9      4   \n",
       "58  250.40  2232        3.0             6.4               5.26     4      7   \n",
       "59  264.88  1758        4.0             6.9               3.39     2      4   \n",
       "60  288.54  1520        3.0             6.9               3.36     4      2   \n",
       "61   55.47  1851        1.0             7.0              13.13    10      4   \n",
       "62  276.68  2234        1.0             6.4               5.69     6      6   \n",
       "63  233.89  2081        1.0             7.6               5.02     3      4   \n",
       "64  276.63  2006        2.0             8.7               3.22     4      8   \n",
       "65  191.93  1694        3.0             5.0               4.69     5     10   \n",
       "66  274.55  1768        3.0             6.8               4.76     2      4   \n",
       "67   75.30  1922        1.0             6.6               3.78     8      2   \n",
       "68  249.91  1820        3.0             4.1               4.94     7      2   \n",
       "70  206.31  1886        3.0             7.1               4.01     7      2   \n",
       "71  260.45  1632        4.0             7.3               4.42     9      3   \n",
       "\n",
       "    clouds  precipitation  misery index  ice cream sold   haunted  \n",
       "0     1.00           0.82         12.99             273 -0.596150  \n",
       "1     1.00           0.99         16.77             184 -0.146465  \n",
       "2     1.00           1.17         16.49             141 -0.303117  \n",
       "3     0.13           0.92          8.28             146  0.339912  \n",
       "4     1.00           1.73          5.90             178  0.724867  \n",
       "5     0.89           1.37          8.59             186  0.805338  \n",
       "6     1.00           0.90         16.55             259 -0.341216  \n",
       "7     0.40           0.88          6.07             105  0.182997  \n",
       "8     1.00           0.90          6.79             317  0.301654  \n",
       "9     1.00           0.91          7.32             285  0.152310  \n",
       "10    0.79           1.58         16.60             178 -0.045025  \n",
       "11    1.00           1.56         15.48             287  0.039757  \n",
       "12    1.00           1.32          5.77             263 -0.073846  \n",
       "13    0.61           1.76         14.29             213 -0.483913  \n",
       "15    1.00           1.81         19.58             182  0.326364  \n",
       "16    0.21           1.16          5.29              96  0.143042  \n",
       "17    0.57           1.28          9.46             122  0.031958  \n",
       "18    1.00           1.02         13.34             253 -0.503893  \n",
       "19    1.00           0.73         18.30             171  0.386117  \n",
       "20    0.91           1.01          7.46             226  0.434018  \n",
       "21    1.00           1.31          7.75             181  0.304909  \n",
       "22    1.00           1.15          8.29             226 -0.197762  \n",
       "23    1.00           1.67         10.54             158 -0.178683  \n",
       "24    1.00           1.18         14.91             253 -1.018351  \n",
       "25    0.73           1.32         14.45             101  0.575107  \n",
       "27    0.57           0.84          5.43              51 -0.281103  \n",
       "28    0.57           1.31          5.78              76  0.265246  \n",
       "29    1.00           0.42         10.00             269 -0.355040  \n",
       "30    1.00           1.12          7.93             191  0.183129  \n",
       "31    1.00           0.93          5.01             235 -0.085612  \n",
       "..     ...            ...           ...             ...       ...  \n",
       "41    1.00           1.14          8.22             308  0.147214  \n",
       "42    1.00           0.64         19.78             199 -0.128244  \n",
       "43    1.00           1.24         15.86             190  0.791066  \n",
       "44    0.78           0.50          5.43              77  0.087057  \n",
       "45    0.36           0.55         14.34             104  0.112670  \n",
       "46    1.00           1.35          9.97             231 -6.559669  \n",
       "47    1.00           0.98         11.87             189 -0.342452  \n",
       "48    1.00           2.38         11.71             258 -0.155856  \n",
       "49    0.21           0.66         20.49               6  0.515447  \n",
       "50    0.11           0.91         10.51             183  0.154788  \n",
       "51    0.21           1.38         20.51             104  0.108915  \n",
       "52    0.84           0.88          5.60             219  0.383989  \n",
       "53    1.00           0.72         16.78             200  0.045433  \n",
       "54    0.54           0.95         20.21             192  0.256072  \n",
       "55    0.40           1.47         11.33              74  0.491245  \n",
       "56    0.30           0.82          8.83              76  0.135198  \n",
       "57    0.80           0.47         20.46             241 -0.023704  \n",
       "58    0.12           1.55         14.39              65  0.172955  \n",
       "59    0.71           1.06          5.83             229  0.278635  \n",
       "60    1.00           1.18         18.48             146  0.167039  \n",
       "61    1.00           1.96         15.33             268 -0.550824  \n",
       "62    1.00           1.14          7.83             313  0.227861  \n",
       "63    0.89           1.00         14.98             216 -0.014516  \n",
       "64    1.00           0.96         20.89             286  0.224601  \n",
       "65    1.00           0.57         18.74             331  0.314783  \n",
       "66    1.00           1.38         11.17             116  0.534418  \n",
       "67    1.00           2.16          6.85             271  0.212597  \n",
       "68    0.60           1.67         16.83             211 -0.024468  \n",
       "70    1.00           1.46         19.44             122  0.219241  \n",
       "71    0.88           0.74          9.41             152  0.546907  \n",
       "\n",
       "[69 rows x 12 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfHouses = pd.read_csv(\"D:\\Valentine\\CU\\CSCI-3022\\Practicum_2\\houses.csv\")\n",
    "dfHouses = dfHouses.dropna()\n",
    "\n",
    "dfHouses.head(1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Perform the appropriate statistical test at the $\\alpha = 0.01$ significance level to determine if _at least one_ of the features is related to the the response $y$.  Clearly describe your methodology and show all computations in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0: B_1 = B_2 = B_3 = B_4 = B_5 = B_6 = B_7 = B_8 = B_9 = B_{10} = B_{11} = 0$\n",
    "\n",
    "$H_1: B_k \\ne 0$ for at least one value of k in 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code that we went over in notebook 23 I am creating an OLS (Ordinary Least Squares) model. For the response I am using the \"haunted\" column and the features will be all of the other columns from the data frame. A P>|t| value less than our .01 significance level will indicate that there is a relationship between the feature and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>haunted</td>     <th>  R-squared:         </th> <td>   0.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.938</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   94.60</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 01 May 2019</td> <th>  Prob (F-statistic):</th> <td>1.97e-32</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:30:47</td>     <th>  Log-Likelihood:    </th> <td>  13.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    69</td>      <th>  AIC:               </th> <td>  -3.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    57</td>      <th>  BIC:               </th> <td>   23.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>    0.3480</td> <td>    0.323</td> <td>    1.078</td> <td> 0.285</td> <td>   -0.298</td> <td>    0.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>               <td>    0.0017</td> <td>    0.000</td> <td>    5.859</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>area</th>              <td>  5.83e-05</td> <td> 6.16e-05</td> <td>    0.946</td> <td> 0.348</td> <td>-6.51e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>         <td>   -0.0411</td> <td>    0.023</td> <td>   -1.806</td> <td> 0.076</td> <td>   -0.087</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance metro</th>    <td>   -0.0142</td> <td>    0.032</td> <td>   -0.443</td> <td> 0.660</td> <td>   -0.079</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance cemetery</th> <td>   -0.1000</td> <td>    0.003</td> <td>  -30.867</td> <td> 0.000</td> <td>   -0.106</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cats</th>              <td>    0.0316</td> <td>    0.010</td> <td>    3.258</td> <td> 0.002</td> <td>    0.012</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>howls</th>             <td>    0.0056</td> <td>    0.011</td> <td>    0.494</td> <td> 0.623</td> <td>   -0.017</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>clouds</th>            <td>    0.0902</td> <td>    0.123</td> <td>    0.734</td> <td> 0.466</td> <td>   -0.156</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>precipitation</th>     <td>    0.0068</td> <td>    0.067</td> <td>    0.102</td> <td> 0.919</td> <td>   -0.128</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>misery index</th>      <td>   -0.0082</td> <td>    0.006</td> <td>   -1.456</td> <td> 0.151</td> <td>   -0.020</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ice cream sold</th>    <td>   -0.0006</td> <td>    0.001</td> <td>   -1.274</td> <td> 0.208</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.629</td> <th>  Durbin-Watson:     </th> <td>   2.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.443</td> <th>  Jarque-Bera (JB):  </th> <td>   1.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.230</td> <th>  Prob(JB):          </th> <td>   0.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.450</td> <th>  Cond. No.          </th> <td>2.55e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.55e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                haunted   R-squared:                       0.948\n",
       "Model:                            OLS   Adj. R-squared:                  0.938\n",
       "Method:                 Least Squares   F-statistic:                     94.60\n",
       "Date:                Wed, 01 May 2019   Prob (F-statistic):           1.97e-32\n",
       "Time:                        14:30:47   Log-Likelihood:                 13.575\n",
       "No. Observations:                  69   AIC:                            -3.151\n",
       "Df Residuals:                      57   BIC:                             23.66\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const                 0.3480      0.323      1.078      0.285      -0.298       0.994\n",
       "age                   0.0017      0.000      5.859      0.000       0.001       0.002\n",
       "area                5.83e-05   6.16e-05      0.946      0.348   -6.51e-05       0.000\n",
       "bathrooms            -0.0411      0.023     -1.806      0.076      -0.087       0.004\n",
       "distance metro       -0.0142      0.032     -0.443      0.660      -0.079       0.050\n",
       "distance cemetery    -0.1000      0.003    -30.867      0.000      -0.106      -0.093\n",
       "cats                  0.0316      0.010      3.258      0.002       0.012       0.051\n",
       "howls                 0.0056      0.011      0.494      0.623      -0.017       0.029\n",
       "clouds                0.0902      0.123      0.734      0.466      -0.156       0.336\n",
       "precipitation         0.0068      0.067      0.102      0.919      -0.128       0.141\n",
       "misery index         -0.0082      0.006     -1.456      0.151      -0.020       0.003\n",
       "ice cream sold       -0.0006      0.001     -1.274      0.208      -0.002       0.000\n",
       "==============================================================================\n",
       "Omnibus:                        1.629   Durbin-Watson:                   2.191\n",
       "Prob(Omnibus):                  0.443   Jarque-Bera (JB):                1.480\n",
       "Skew:                           0.230   Prob(JB):                        0.477\n",
       "Kurtosis:                       2.450   Cond. No.                     2.55e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.55e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = dfHouses[\"haunted\"], dfHouses.iloc[:,:11] \n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit() \n",
    "slopesFull = model.params\n",
    "model.summary()\n",
    "#print(model.fstatistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER PART B**\n",
    "\n",
    "We can see from the OLS model that there is a relationship between the number of cats and the response, the age of the house and the response, and the distance to the cemetery and the response. Thus, we will reject the Null Hypothesis and say that there is at least one feature that relates to the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part C**: Write a function `forward_select(df, resp_str, maxk)` that takes in the DataFrame, the name of the column corresponding to the response, and the maximum number of desired features, and returns a list of feature names corresponding to the `maxk` most important features via forward selection.  At each stage in forward selection you should add the feature whose inclusion in the model would result in the lowest sum of squared errors $(SSE)$. Use your function to determine the best $k=5$ features to include in the model. Clearly indicate which feature was added in each stage. \n",
    "\n",
    "**Note**: The point of this exercise is to see if you can implement **foward_select** yourself.  You may of course use canned routines like statmodels OLS, but you may not call any Python method that explicitly performs forward selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added distance cemetery as a feature\n",
      "Added age as a feature\n",
      "Added cats as a feature\n",
      "Added bathrooms as a feature\n",
      "Added misery index as a feature\n",
      "['distance cemetery', 'age', 'cats', 'bathrooms', 'misery index']\n"
     ]
    }
   ],
   "source": [
    "def forward_select(df, resp_str, maxk):\n",
    "    slopes = []\n",
    "    intercepts = []\n",
    "    SSE = 0\n",
    "    tempSSE = 0\n",
    "    position = 0\n",
    "    positions = []\n",
    "    bestFeatures = []\n",
    "\n",
    "\n",
    "    variables = [\"age\", \"area\", \"bathrooms\", \"distance metro\", \"distance cemetery\", \"cats\", \"howls\", \"clouds\", \"precipitation\", \"misery index\", \"ice cream sold\"]\n",
    "    for v in variables: \n",
    "        #print(\"SLR for {} vs hauntedness\".format(v))\n",
    "        #print(\"----------------------\")\n",
    "        bhat, ahat, rval, pval, stderr = stats.linregress(df[v], df[resp_str])\n",
    "        slopes.append(bhat)\n",
    "        intercepts.append(ahat)\n",
    "        #print(\"intercept = {:.4f}\".format(ahat))\n",
    "        #print(\"slope = {:.4f}\".format(bhat))\n",
    "        #print(\"p-value = {}\".format(pval))\n",
    "        #print(\"\\n\")\n",
    "\n",
    "\n",
    "    # Baseline SSE\n",
    "    for i in range (69):\n",
    "        SSE = SSE + ((df.iloc[i,11] - 1)**2)\n",
    "\n",
    "    # Adding the best feature using SSE simple linear regression\n",
    "    for i in range (11):\n",
    "        slope = slopes[i]\n",
    "        intercept = intercepts[i]\n",
    "        for j in range (69):\n",
    "            tempSSE = tempSSE + ((df.iloc[j,11] - (intercept + (slope*df.iloc[j,i])))**2)\n",
    "        if (tempSSE < SSE):\n",
    "            SSE = tempSSE\n",
    "            position = i\n",
    "        tempSSE = 0\n",
    "    print(\"Added {} as a feature\" .format(variables[position]))\n",
    "    positions.append(position)\n",
    "    bestFeatures.append(variables[position])\n",
    "    \n",
    "    bigX = df.iloc[:,positions[0]:positions[0]+1]\n",
    "    \n",
    "    # Adding the remaining features using R squred MLR\n",
    "    for i in range (maxk-1):\n",
    "        r = 0\n",
    "        for j in range (11):\n",
    "            valid = True\n",
    "            for k in range(len(positions)):\n",
    "                if (j == positions[k]):\n",
    "                    valid = False\n",
    "            if (valid == True):\n",
    "                tempR = 0\n",
    "                y = df[resp_str]\n",
    "                X = bigX\n",
    "                X = X.join(df.iloc[:,j])\n",
    "                X = sm.add_constant(X)\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                tempR = model.rsquared\n",
    "                if (tempR > r):\n",
    "                    r = tempR\n",
    "                    position = j\n",
    "        bigX = bigX.join(df.iloc[:,position])\n",
    "        print(\"Added {} as a feature\" .format(variables[position]))\n",
    "        bestFeatures.append(variables[position])\n",
    "        positions.append(position)\n",
    "    \n",
    "    return(bestFeatures)\n",
    "\n",
    "print(forward_select(dfHouses,\"haunted\",5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>haunted</td>     <th>  R-squared:         </th> <td>   0.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   218.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 01 May 2019</td> <th>  Prob (F-statistic):</th> <td>2.00e-38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:30:51</td>     <th>  Log-Likelihood:    </th> <td>  11.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    69</td>      <th>  AIC:               </th> <td>  -11.86</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    63</td>      <th>  BIC:               </th> <td>   1.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>    0.3456</td> <td>    0.107</td> <td>    3.220</td> <td> 0.002</td> <td>    0.131</td> <td>    0.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>               <td>    0.0018</td> <td>    0.000</td> <td>    6.506</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance cemetery</th> <td>   -0.1005</td> <td>    0.003</td> <td>  -32.801</td> <td> 0.000</td> <td>   -0.107</td> <td>   -0.094</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cats</th>              <td>    0.0327</td> <td>    0.009</td> <td>    3.545</td> <td> 0.001</td> <td>    0.014</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bathrooms</th>         <td>   -0.0382</td> <td>    0.022</td> <td>   -1.747</td> <td> 0.085</td> <td>   -0.082</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>misery index</th>      <td>   -0.0087</td> <td>    0.005</td> <td>   -1.592</td> <td> 0.116</td> <td>   -0.020</td> <td>    0.002</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.395</td> <th>  Durbin-Watson:     </th> <td>   2.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.498</td> <th>  Jarque-Bera (JB):  </th> <td>   1.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.289</td> <th>  Prob(JB):          </th> <td>   0.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.595</td> <th>  Cond. No.          </th> <td>    739.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                haunted   R-squared:                       0.946\n",
       "Model:                            OLS   Adj. R-squared:                  0.941\n",
       "Method:                 Least Squares   F-statistic:                     218.7\n",
       "Date:                Wed, 01 May 2019   Prob (F-statistic):           2.00e-38\n",
       "Time:                        14:30:51   Log-Likelihood:                 11.932\n",
       "No. Observations:                  69   AIC:                            -11.86\n",
       "Df Residuals:                      63   BIC:                             1.541\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const                 0.3456      0.107      3.220      0.002       0.131       0.560\n",
       "age                   0.0018      0.000      6.506      0.000       0.001       0.002\n",
       "distance cemetery    -0.1005      0.003    -32.801      0.000      -0.107      -0.094\n",
       "cats                  0.0327      0.009      3.545      0.001       0.014       0.051\n",
       "bathrooms            -0.0382      0.022     -1.747      0.085      -0.082       0.005\n",
       "misery index         -0.0087      0.005     -1.592      0.116      -0.020       0.002\n",
       "==============================================================================\n",
       "Omnibus:                        1.395   Durbin-Watson:                   2.178\n",
       "Prob(Omnibus):                  0.498   Jarque-Bera (JB):                1.434\n",
       "Skew:                           0.289   Prob(JB):                        0.488\n",
       "Kurtosis:                       2.595   Cond. No.                         739.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, X = dfHouses[\"haunted\"], dfHouses.iloc[:,[0,4,5,2,9]] \n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit() \n",
    "slopesRed = model.params\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part D**: Write down the multiple linear regression model, including estimated parameters, obtained by your forward selection process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**ANSWER PART D**\n",
    "\n",
    "$haunted = 0.3456 - (0.1005*Distance Cemetery) + (0.0018*Age)  + (0.0327*Cats) - (0.0382*Bathrooms) - (0.0087*Misery Index)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part E**: Perform the appropriate statistical test at the $\\alpha = 0.05$ significance level to determine whether there is a statistically significant difference between the full model with all features and the reduced model obtained by forward selection in **Part D**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER PART E**\n",
    "\n",
    "$H_0: B_1 = B_3 = B_5 = B_6 = B_7 = B_8 = B_{10} = 0$\n",
    "\n",
    "$H_1: B_k \\ne 0$ for at least one value of k in 1, 3, 5, 6, 7, 8, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46348704337579594\n"
     ]
    }
   ],
   "source": [
    "SSEF = 0\n",
    "SSER = 0\n",
    "for i in range (69):\n",
    "    SSEF = SSEF + (dfHouses.iloc[i,11] - (slopesFull[0] + (slopesFull[1]*dfHouses.iloc[i,0]) + (slopesFull[2]*dfHouses.iloc[i,1]) + (slopesFull[3]*dfHouses.iloc[i,2]) + (slopesFull[4]*dfHouses.iloc[i,3]) + (slopesFull[5]*dfHouses.iloc[i,4]) + (slopesFull[6]*dfHouses.iloc[i,5]) + (slopesFull[7]*dfHouses.iloc[i,6]) + (slopesFull[8]*dfHouses.iloc[i,7]) + (slopesFull[9]*dfHouses.iloc[i,8]) + (slopesFull[10]*dfHouses.iloc[i,9]) + (slopesFull[11]*dfHouses.iloc[i,10])))**2\n",
    "for i in range (69):\n",
    "    SSER = SSER + (dfHouses.iloc[i,11] - (slopesRed[0] + (slopesRed[1]*dfHouses.iloc[i,0])  + (slopesRed[2]*dfHouses.iloc[i,4]) + (slopesRed[3]*dfHouses.iloc[i,5]) + (slopesRed[4]*dfHouses.iloc[i,2]) + (slopesRed[5]*dfHouses.iloc[i,9])))**2\n",
    "\n",
    "F = ((SSER - SSEF)/(11-5))/((SSEF)/(69-11-1))\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $0.463487 > \\alpha$ with $\\alpha = .05$ we fail to reject the Null Hypothesis and can say that there is no statistically significant difference between the full model and the reduced model at the $\\alpha = 0.05$ significance level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part F**: Based on your conclusions in **Part E**, use the _better_ of the two models to predict the sharknado hazard when the following features are observed: \n",
    "\n",
    "- $\\texttt{age}$: 100 years\n",
    "- $\\texttt{area}$: 2200 square feet\n",
    "- $\\texttt{bathrooms}$: 3 bathrooms\n",
    "- $\\texttt{distance metro}$: 25 miles\n",
    "- $\\texttt{distance cemetery}$: 10 miles\n",
    "- $\\texttt{cats}$: 4 cats\n",
    "- $\\texttt{howls}$: 5 wolf howls/night\n",
    "- $\\texttt{clouds}$: 0.65 cloud cover\n",
    "- $\\texttt{precipitation}$: 0 inches\n",
    "- $\\texttt{misery index}$: 10\n",
    "- $\\texttt{ice cream sold}$: 125"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**ANSWER PART F**\n",
    "\n",
    "Because the adjusted Rscore from the partial model is higher than the adjusted Rscore of the full model, we can say it is the better model for making a prediction.\n",
    "\n",
    "we recall our formula from Part D\n",
    "\n",
    "$Sharknado? = 0.3456 - (0.1005*Distance Cemetery) + (0.0018*Age)  + (0.0327*Cats) - (0.0382*Bathrooms) - (0.0087*Misery Index)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5502000000000001\n"
     ]
    }
   ],
   "source": [
    "haunted = (.3456 - (.1005 * 10) + (.0018 * 100) + (.0327 * 4) - (.0382 * 3) - (.0087 * 10))\n",
    "print(haunted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yields -0.5502... meaning that the likelyhood of a localized sharknado event is relatively low on the Front Range compared to our dataset, i.e. most of the values in our original dataframe.\n",
    "\n",
    "Also, I think you meant haunted not sharknado but I'm rolling with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part G:** Governor Polis dabbles a bit in the art of data science, as well as the science of data art. He tells you that the response (`haunted` score) that you and Amy predicted is actually the natural logarithm of the _odds_ that a house with the given features is haunted, where if $p$ is the probability that a house is haunted, then the odds are given by $$\\text{odds} = \\dfrac{p}{1-p}$$\n",
    "\n",
    "What transformation must you make in order to turn your multiple regression model into a logistic regression model, to classify a house a haunted or not? Perform this simple transformation, then use a decision threshold of 0.5 to classify the house from **Part F** as haunted or not haunted. No new models should be fit here; use the same model that you used in Part F."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER PART G**\n",
    "\n",
    "In order to transform to a logistic regression model we use the following math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the probability of a house being haunted is 0.36224489795918363 and the odds are 0.5768344319566375\n"
     ]
    }
   ],
   "source": [
    "odds = np.exp(-.5502)\n",
    "p = (.568/1.568)\n",
    "print(\"the probability of a house being haunted is {} and the odds are {}\" .format(p,odds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, using a 0.5 decision threshold we can say that the house is not haunted... and probably won't be hit by a sharknado either :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "[Back to top](#top)\n",
    "<a id='bot'></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
